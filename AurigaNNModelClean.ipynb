{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various imports we use\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.callbacks\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40000\n"
     ]
    }
   ],
   "source": [
    "#This is a very basic example of loading some data, training the model, and \n",
    "#performing predictions on a test dataset\n",
    "\n",
    "### These first few lines are specifically for the utils.import_data method, and aren't strictly necessary\n",
    "### if you have your own pipeline.\n",
    "########################\n",
    "#Selected Auriga halo\n",
    "HALO = 14\n",
    "#Total number of training particles\n",
    "N_TRAINING = 80000\n",
    "#maximum alpha/Fe allowed, due to low Fe this is required\n",
    "alphaMax = 1e10\n",
    "#noise to add to chemical data\n",
    "NOISE = 0\n",
    "#columns of data to drop/ignore before feeding into the model\n",
    "DROP_COL = ['X','Y','Z','M','R', 'epsJ', 'Ne', 'Mg', 'C','N','He', 'Si', 'O', 'z', 'Vr', 'BE', 'Lz', 'pkmassid'] #\n",
    "\n",
    "\n",
    "#Import the disc's data, and make a full copy with all the information for later\n",
    "training_data = utils.import_data(to_drop = [], dat=False,alpha_max=alphaMax,chem_noise = NOISE)\n",
    "\n",
    "#Remove the to-drop data from the set we'll continue with\n",
    "data = training_data.drop(DROP_COL, axis=1)\n",
    "\n",
    "#If you're loading from multiple sources, you can construct multiple datasets with a loop\n",
    "#combine them into a list data_app = [tdata1, tdata2,...]\n",
    "#and the concatenate them into a combined training set!\n",
    "#We then use .sample(frac=1) to shuffle everything\n",
    "data_app = [data]\n",
    "data_t = pd.concat(data_app,ignore_index=True).sample(frac=1)\n",
    "\n",
    "#Important for GANN is that this training data is uniformly considered to be accreted\n",
    "#EVEN IF IT's NOT TRUE!\n",
    "#This is mimicking observational constraints\n",
    "#Not to mention, this training set should be halo and satellite stars,\n",
    "#Sats are obviously really \"accreted\", but the halo should be >99%\n",
    "#So we set the acc_label column to a ones vector of the same size\n",
    "data_t['acc_label'] = np.ones(data_t.index.values.shape[0])\n",
    "\n",
    "#Now, we want the length of the training data, so that we can sample an equal number\n",
    "#of particles from the test data set (the disc!)\n",
    "#You can, alternatively, generate your own in-situ training data,\n",
    "#using clever slices of stars to minimize the chance of contamination\n",
    "#but for the paper I didn't, because examining worst-cases is more interesting\n",
    "N = data_t.index.shape[0]\n",
    "N = int(min(N,N_TRAINING/2)) #If N > the number we want, we'll subsample\n",
    "acc_dat = data_t.sample(n=N) #this will just shuffle if N <= N_TRAINING\n",
    "#We've now generated the accreted half of our training set!\n",
    "#Now on to the in-situ, which we'll sample from the \"evaluation\" disc data\n",
    "#under the assumption that f_acc in the disc is low.\n",
    "#Not technically safe, but we're pretending to be more constrained than we are!\n",
    "#there *will* be contamination, because f_acc *should* be > 0 (otherwise it's a boring search haha)\n",
    "\n",
    "#Make a full copy - for use in visualization of correlations, etc.\n",
    "#This is *very* useful, as you can train the model on the restricted set,\n",
    "#create filters based on the labels, and apply those filters to the \n",
    "#full testing set! That way you can examine values that you don't\n",
    "#use in the network itself\n",
    "test_dat_full = utils.import_data(to_drop = [], dat=True, alpha_max=alphaMax,chem_noise = NOISE)\n",
    "#Grab a chunk of data to use in the training set\n",
    "#the number should match the size of the accreted contribution\n",
    "print(\"Using %d\"%(N))\n",
    "ins_dat = test_dat_full.sample(n=N)\n",
    "#remove unncessary columns from in-situ training data\n",
    "ins_dat = ins_dat.drop(DROP_COL, axis=1)\n",
    "#for the training data, we set its label to 0\n",
    "ins_dat['acc_label'] = np.zeros(ins_dat.index.values.shape[0])\n",
    "\n",
    "#build the full training set by concatenating the acc and ins data\n",
    "train_dat = pd.concat([acc_dat, ins_dat],ignore_index=True).sample(frac=1)\n",
    "#we pop off the labels for comparison/validation\n",
    "train_lab = train_dat.pop('acc_label')\n",
    "\n",
    "#We take the rest and create the validation set, with labels\n",
    "test_dat = test_dat_full.copy()\n",
    "#Once again, remove the unneeded columns from the data\n",
    "test_dat = test_dat.drop(DROP_COL, axis=1)\n",
    "#and pop off the labels for later!\n",
    "test_lab = test_dat.pop('acc_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2700 - accuracy: 0.8936 - false_positives_6: 2979.2363\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2316 - accuracy: 0.9118 - false_positives_6: 2824.6605\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2332 - accuracy: 0.9091 - false_positives_6: 2877.5722\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2255 - accuracy: 0.9142 - false_positives_6: 2810.3259\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2249 - accuracy: 0.9137 - false_positives_6: 2842.5910\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2238 - accuracy: 0.9144 - false_positives_6: 2814.6781\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2227 - accuracy: 0.9140 - false_positives_6: 2819.9816\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2224 - accuracy: 0.9151 - false_positives_6: 2817.6489\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2202 - accuracy: 0.9165 - false_positives_6: 2708.5250\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2225 - accuracy: 0.9145 - false_positives_6: 2834.2895\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2243 - accuracy: 0.9140 - false_positives_6: 2818.8357\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2200 - accuracy: 0.9162 - false_positives_6: 2786.6573\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2192 - accuracy: 0.9172 - false_positives_6: 2732.0044\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2221 - accuracy: 0.9140 - false_positives_6: 2804.8037\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2207 - accuracy: 0.9149 - false_positives_6: 2830.0860\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2245 - accuracy: 0.9137 - false_positives_6: 2826.4986\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2153 - accuracy: 0.9177 - false_positives_6: 2748.6617\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2210 - accuracy: 0.9155 - false_positives_6: 2776.0992\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2161 - accuracy: 0.9176 - false_positives_6: 2779.6369\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2243 - accuracy: 0.9132 - false_positives_6: 2834.6433\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2199 - accuracy: 0.9157 - false_positives_6: 2765.9428\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.2224 - accuracy: 0.9145 - false_positives_6: 2727.0552\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.2199 - accuracy: 0.9156 - false_positives_6: 2734.7581A: 1s - loss: 0.2205 - accuracy\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2176 - accuracy: 0.9167 - false_positives_6: 2732.3571\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2231 - accuracy: 0.9153 - false_positives_6: 2731.7209\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2152 - accuracy: 0.9175 - false_positives_6: 2709.5306\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2183 - accuracy: 0.9155 - false_positives_6: 2763.2823\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2234 - accuracy: 0.9119 - false_positives_6: 2882.0992\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2211 - accuracy: 0.9144 - false_positives_6: 2773.4514\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2205 - accuracy: 0.9147 - false_positives_6: 2748.9896\n"
     ]
    }
   ],
   "source": [
    "Nmul = 1\n",
    "N_NEURON_BASE = 32\n",
    "#Here we define the model's layers\n",
    "#I've set it up to use the length of the training data's keys as the input vector size,\n",
    "#which means the network will adjust as you add/remove data columns\n",
    "model = tf.keras.Sequential([\n",
    "    #the batchnorm layer will help with performance a ton, and prevent \n",
    "    #larger input values from initially dominating while the network\n",
    "    #\"learns\" to adjust those weights\n",
    "    tf.keras.layers.BatchNormalization(input_shape=[len(train_dat.keys())]),  \n",
    "    #Next are all dense (interconnected) layers, where the deep-learning happens\n",
    "    tf.keras.layers.Dense(Nmul * 2 * N_NEURON_BASE,activation=tf.nn.selu,kernel_initializer=tf.keras.initializers.lecun_normal(seed=None)),\n",
    "    tf.keras.layers.Dense(Nmul * 8 * N_NEURON_BASE,activation=tf.nn.selu,kernel_initializer=tf.keras.initializers.lecun_normal(seed=None)),\n",
    "    tf.keras.layers.Dense(Nmul * 2 * N_NEURON_BASE,activation=tf.nn.selu,kernel_initializer=tf.keras.initializers.lecun_normal(seed=None)), ##New\n",
    "    tf.keras.layers.Dense(Nmul * N_NEURON_BASE,activation=tf.nn.selu,kernel_initializer=tf.keras.initializers.lecun_normal(seed=None)),\n",
    "    #finally, our output uses a single sigmoid neuron to output a probability-like value\n",
    "    #(can't say probability, because a statistician might get mad)\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "#the compilation info\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              #We use BCE, because it's perfect for this use-case\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "              #We sorta care about accuracy, but definitely about false positives\n",
    "              metrics=['accuracy',tf.keras.metrics.FalsePositives(thresholds=0.5)])\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "#Set up early stopping and plateau learning-rate reduction\n",
    "#optional, and can sometimes make the model give up on improving\n",
    "#earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, verbose=0, mode='auto',restore_best_weights=True)\n",
    "#reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=0, verbose=1, epsilon=1e-4, mode='min')\n",
    "#and here we execute the fitting procedure, and save the model\n",
    "model.fit(train_dat, train_lab, epochs=30)#, callbacks=[earlyStopping,reduce_lr_loss])\n",
    "model.save(\"models/auriga_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  0.6814622746114873\n",
      "Incorrect:  0.10726104979444226\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEnCAYAAABL6S/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWd0lEQVR4nO3de5QnZX3n8feH4a7cGVyYQZroJMeBXUBHxNWNBFgY0AP8IQZODKPLLmcJ7lHXzQrJniVROUouomZRQxYW8AaEaJjosEi4HBIVZBAEAVlGnMDIbWAucgko8N0/6hnzO0339K+n793v1zl1uuqpp6qep3umP7+qp6o6VYUkaW7baqobIEmaeoaBJMkwkCQZBpIkDANJEoaBJAnDQJpUSVYnOWqq2yENZhhoRklyU5L1SbabgmMfnmTNBO5/YZK/SfJkko1J7k7yvrZuIEkl2Xqijq+5zTDQjJFkAPh3QAHHT8D+5433PkfpS8DDwH7AHsCpwOPjsWNDRCMxDDSTnArcAlwCLOtdkWSHJH+e5J/ap+p/TLJDW/f2JN9NsiHJwz2fti9J8oUkK5I8C/xWku2S/FmSh5I8nuSLbd+vAq4B9knyTJv2SbJVkrOS/CTJU0muTLJ7T7t+t7XpqSR/OEL/3gxcUlXPVtWLVXVHVV3T1t3cvm5ox35rktcluaHt+8kkX0mya8+xVyf5aJK7gGeTbN2Wf5bk6ST3JzlyC38Wmm2qyslpRkzAKuD3gDcBvwRe07PuAuAmYAEwD/i3wHbAa4GngVOAbeg+cR/ctrkE2Ai8je6D0fbAZ4DlwO7ATsDfAZ9s9Q8H1gxq04foAmphO95fAl9r6xYDzwC/2dZ9GngROGqY/v098B3gZOC1g9YN0J0Rbd1T9nrg37d9z6cLjM/0rF8N3AnsC+wA/Abdmcc+Pft83VT/XJ2mxzTlDXBy6mcC3t4CYM+2/GPgw21+K+CfgYOG2O5s4BvD7PMS4LKe5QDP9v6CBN4K/LTNDxUG9wFH9izv3dq5NfA/gct71r0K+MVmwmA34FPAPcBL7Rf5m9u6V4TBENufCNzRs7wa+A89y68HngCOAraZ6p+p0/SavEykmWIZ8O2qerItf5V/uVS0J92n+p8Msd2+w5Rv8nDP/HxgR+D2dklpA/B/W/lw9gO+0VP/Prpf5K8B9undf1U9Czw13I6qan1VnVVVB7Tt7wT+NkmGqp9krySXt8s+Pwe+TPe9GLJ/VbWK7kzmj4An2rb7bKZvmkMMA0177dr/e4B3JHksyWPAh4GDkhwEPAk8D7xuiM0fHqZ8k97X9j5Jd4ZxQFXt2qZdqurVQ9Tt3f+xPfV3rartq+pnwKN0YbSpHzvSXaYaUQu9P6MLlN2HOfYnW/m/qaqdgffSnd0M1z+q6qtV9Xa6ECvgvH7ao9nPMNBMcCLdp+3FwMFtegPwD8CpVfUycDHw6TaoO68NsG4HfAU4Ksl72gDqHkkOHuogbT9/BZyfZC+AJAuSHNOqPA7skWSXns2+CJybZL9Wf36SE9q6q4B3tQHsbYGPsZn/c0nOS3Jga+dOwBnAqqp6ClgLvAz8Ws8mO9GNSWxIsgD4/c19E5P8RpIj2vflebrge2lz22juMAw0EywD/k9VPVRVj22agP8F/E67bfK/AXcDtwHr6D7xblVVDwHHAR9p5XcCB23mWB+lG6i+pV16+Xu6gVeq6sfA14AH22WhfYDP0g04fzvJ03SDyW9p9e8BzqS7pPUosB7Y3HMKOwLfADYAD9J9ej++7es54FzgO+3YhwF/DLyRbhD8W8DXR/g+bkc3JvEk8BiwF/AHI2yjOSJV/nEbSZrrPDOQJBkGkiTDQJKEYSBJwjCQJNE9Mj8j7bnnnjUwMDDVzZCkGeP2229/sqqGfKJ+xobBwMAAK1eunOpmSNKMkeSfhlvnZSJJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDGDn0CWpOlo4Kxvjar+6k+9c4JaMjqeGUiSDANJkmEgScIwkCRhGEiSMAwkSRgGkiR8zkCSNmu0zw3MVJ4ZSJIMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKjCIMk85LckeSbbXn/JLcmeSDJFUm2beXbteVVbf1Azz7ObuX3Jzmmp3xpK1uV5Kzx654kqR+jOTP4IHBfz/J5wPlVtQhYD5zWyk8D1lfV64HzWz2SLAZOBg4AlgKfbwEzD7gAOBZYDJzS6kqSJklfYZBkIfBO4H+35QBHAFe1KpcCJ7b5E9oybf2Rrf4JwOVV9UJV/RRYBRzaplVV9WBV/QK4vNWVJE2Sfs8MPgP8d+DltrwHsKGqXmzLa4AFbX4B8DBAW7+x1f9V+aBthiuXJE2SEcMgybuAJ6rq9t7iIarWCOtGWz5UW05PsjLJyrVr126m1ZKk0ejnzOBtwPFJVtNdwjmC7kxh1ySb3nq6EHikza8B9gVo63cB1vWWD9pmuPJXqKoLq2pJVS2ZP39+H02XJPVjxDCoqrOramFVDdANAN9QVb8D3Ai8u1VbBlzd5pe3Zdr6G6qqWvnJ7W6j/YFFwPeB24BF7e6kbdsxlo9L7yRJfRnL3zP4KHB5kk8AdwAXtfKLgC8lWUV3RnAyQFXdk+RK4F7gReDMqnoJIMkHgGuBecDFVXXPGNolSRqlUYVBVd0E3NTmH6S7E2hwneeBk4bZ/lzg3CHKVwArRtMWSdL48QlkSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiT7CIMn2Sb6f5IdJ7knyx618/yS3JnkgyRVJtm3l27XlVW39QM++zm7l9yc5pqd8aStbleSs8e+mJGlz+jkzeAE4oqoOAg4GliY5DDgPOL+qFgHrgdNa/dOA9VX1euD8Vo8ki4GTgQOApcDnk8xLMg+4ADgWWAyc0upKkibJiGFQnWfa4jZtKuAI4KpWfilwYps/oS3T1h+ZJK388qp6oap+CqwCDm3Tqqp6sKp+AVze6kqSJklfYwbtE/ydwBPAdcBPgA1V9WKrsgZY0OYXAA8DtPUbgT16ywdtM1y5JGmS9BUGVfVSVR0MLKT7JP+Goaq1rxlm3WjLXyHJ6UlWJlm5du3akRsuSerLqO4mqqoNwE3AYcCuSbZuqxYCj7T5NcC+AG39LsC63vJB2wxXPtTxL6yqJVW1ZP78+aNpuiRpM/q5m2h+kl3b/A7AUcB9wI3Au1u1ZcDVbX55W6atv6GqqpWf3O422h9YBHwfuA1Y1O5O2pZukHn5eHROktSfrUeuwt7Ape2un62AK6vqm0nuBS5P8gngDuCiVv8i4EtJVtGdEZwMUFX3JLkSuBd4ETizql4CSPIB4FpgHnBxVd0zbj2UJI1oxDCoqruAQ4Yof5Bu/GBw+fPAScPs61zg3CHKVwAr+mivJGkC+ASyJMkwkCQZBpIkDANJEoaBJAnDQJJEf88ZSNKsMHDWt6a6CdOWZwaSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRJ9hEGSfZPcmOS+JPck+WAr3z3JdUkeaF93a+VJ8rkkq5LcleSNPfta1uo/kGRZT/mbktzdtvlckkxEZyVJQ+vnzOBF4CNV9QbgMODMJIuBs4Drq2oRcH1bBjgWWNSm04EvQBcewDnAW4BDgXM2BUirc3rPdkvH3jVJUr9GDIOqerSqftDmnwbuAxYAJwCXtmqXAie2+ROAy6pzC7Brkr2BY4DrqmpdVa0HrgOWtnU7V9X3qqqAy3r2JUmaBKMaM0gyABwC3Aq8pqoehS4wgL1atQXAwz2brWllmytfM0S5JGmS9B0GSV4N/A3woar6+eaqDlFWW1A+VBtOT7Iyycq1a9eO1GRJUp/6CoMk29AFwVeq6uut+PF2iYf29YlWvgbYt2fzhcAjI5QvHKL8FarqwqpaUlVL5s+f30/TJUl96OduogAXAfdV1ad7Vi0HNt0RtAy4uqf81HZX0WHAxnYZ6Vrg6CS7tYHjo4Fr27qnkxzWjnVqz74kSZNg6z7qvA34XeDuJHe2sj8APgVcmeQ04CHgpLZuBXAcsAp4Dng/QFWtS/Jx4LZW72NVta7NnwFcAuwAXNMmSdqsgbO+NdVNmDVGDIOq+keGvq4PcOQQ9Qs4c5h9XQxcPET5SuDAkdoiSZoYPoEsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEv39DWRJmhT+TeOp45mBJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJLwCWRJE8gnimcOzwwkSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkiT4eOktyMfAu4ImqOrCV7Q5cAQwAq4H3VNX6JAE+CxwHPAe8r6p+0LZZBvyPtttPVNWlrfxNwCXADsAK4INVVePUP0njyIfIZq9+zgwuAZYOKjsLuL6qFgHXt2WAY4FFbTod+AL8KjzOAd4CHAqck2S3ts0XWt1N2w0+liRpgo0YBlV1M7BuUPEJwKVt/lLgxJ7yy6pzC7Brkr2BY4DrqmpdVa0HrgOWtnU7V9X32tnAZT37kiRNki0dM3hNVT0K0L7u1coXAA/31FvTyjZXvmaIcknSJBrvAeQMUVZbUD70zpPTk6xMsnLt2rVb2ERJ0mBbGgaPt0s8tK9PtPI1wL499RYCj4xQvnCI8iFV1YVVtaSqlsyfP38Lmy5JGmxLw2A5sKzNLwOu7ik/NZ3DgI3tMtK1wNFJdmsDx0cD17Z1Tyc5rN2JdGrPviRJk6SfW0u/BhwO7JlkDd1dQZ8CrkxyGvAQcFKrvoLuttJVdLeWvh+gqtYl+ThwW6v3saraNCh9Bv9ya+k1bZIkTaIRw6CqThlm1ZFD1C3gzGH2czFw8RDlK4EDR2qHJGni+JfOpDnMh8i0ia+jkCQZBpIkw0CShGEgScIwkCTh3UTSrOGdQRoLzwwkSYaBJMnLRJI0pUZ7eW/1p945Ie3wzECSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiS8KEzadryXUOaTIaBNEn85a7pzDCQtpC/3DWbOGYgSTIMJElz9DLRdHlLoCRNF3MyDKShOAaguczLRJIkw0CSZBhIkjAMJEk4gKxZzAFhqX+eGUiSPDPQzOCnfGlieWYgSfLMQFPDT/rS9GIYaFz4y12a2QwDDclf7tLcYhjMEf5yl7Q5hkEf/EUqababNncTJVma5P4kq5KcNdXtkaS5ZFqEQZJ5wAXAscBi4JQki6e2VZI0d0yLMAAOBVZV1YNV9QvgcuCEKW6TJM0Z0yUMFgAP9yyvaWWSpEkwXQaQM0RZvaJScjpwelt8Jsn9W3i8PYEnt3Dbmco+z35zrb8wB/uc88bU5/2GWzFdwmANsG/P8kLgkcGVqupC4MKxHizJyqpaMtb9zCT2efaba/0F+zyepstlotuARUn2T7ItcDKwfIrbJElzxrQ4M6iqF5N8ALgWmAdcXFX3THGzJGnOmBZhAFBVK4AVk3S4MV9qmoHs8+w31/oL9nncpOoV47SSpDlmuowZSJKm0KwOg5FecZFkuyRXtPW3JhmY/FaOnz76+1+T3JvkriTXJxn2NrOZot/XmCR5d5JKMuPvPOmnz0ne037W9yT56mS3cbz18W/7tUluTHJH+/d93FS0c7wkuTjJE0l+NMz6JPlc+37cleSNYz5oVc3KiW4g+ifArwHbAj8EFg+q83vAF9v8ycAVU93uCe7vbwE7tvkzZnJ/++1zq7cTcDNwC7Bkqts9CT/nRcAdwG5tea+pbvck9PlC4Iw2vxhYPdXtHmOffxN4I/CjYdYfB1xD94zWYcCtYz3mbD4z6OcVFycAl7b5q4Ajkwz1ANxMMGJ/q+rGqnquLd5C9zzHTNbva0w+DvwJ8PxkNm6C9NPn/wRcUFXrAarqiUlu43jrp88F7Nzmd2GI55Rmkqq6GVi3mSonAJdV5xZg1yR7j+WYszkM+nnFxa/qVNWLwEZgj0lp3fgb7Ss9TqP7ZDGTjdjnJIcA+1bVNyezYROon5/zrwO/nuQ7SW5JsnTSWjcx+unzHwHvTbKG7q7E/zI5TZsy4/4Kn2lza+kE6OcVF329BmOG6LsvSd4LLAHeMaEtmnib7XOSrYDzgfdNVoMmQT8/563pLhUdTnf29w9JDqyqDRPctonST59PAS6pqj9P8lbgS63PL09886bEuP/ums1nBv284uJXdZJsTXd6ublTs+msr1d6JDkK+EPg+Kp6YZLaNlFG6vNOwIHATUlW011bXT7DB5H7/Xd9dVX9sqp+CtxPFw4zVT99Pg24EqCqvgdsT/feotmqr//vozGbw6CfV1wsB5a1+XcDN1QbnZmBRuxvu2Tyl3RBMNOvI8MIfa6qjVW1Z1UNVNUA3TjJ8VW1cmqaOy76+Xf9t3Q3C5BkT7rLRg9OaivHVz99fgg4EiDJG+jCYO2ktnJyLQdObXcVHQZsrKpHx7LDWXuZqIZ5xUWSjwErq2o5cBHd6eQqujOCk6euxWPTZ3//FHg18NdtnPyhqjp+yho9Rn32eVbps8/XAkcnuRd4Cfj9qnpq6lo9Nn32+SPAXyX5MN3lkvfN4A92JPka3WW+Pds4yDnANgBV9UW6cZHjgFXAc8D7x3zMGfz9kiSNk9l8mUiS1CfDQJJkGEiSDANJEoaBJAnDQJKEYSCNSpJXJXmpvQ67d3o5yVNJrk1y7FS3UxotnzOQRqG99+a7bfHxnlU7ATv2LH+oqj47aQ2TxsgzA2l0DmlfN1bVv9o00T3Z/TZgdVv/ySQz9Q24moMMA2l0NoXB3b2F7b3y3wU+3Ip2oPsDJdKMYBhIo3Nw+3rXMOtv65mfP8FtkcaNYSD1qb3m/MC2OFwYbNMzv3FiWySNH8NA6t+mVyPDoMtEPd7aM//DiW2ONH4MA6l/my4RFUOEQZIdgLPb4g+q6seT1TBprAwDqX+bBo9XV9XTmwqT7NyeLbgZ+NfAC8AHpqB90habtX/cRpoAm8Jg/yTDPaDzBPDe9qcXpRnDh86kPiVZB+wG/Bz451b8It1A8f+j+0tcX66qZ6amhdKW88xA6kOSAbogADipqr49da2Rxp9jBlJ/DumZv6PfjZLsl+TzSX6c5LkkG5L8XZIDJqCN0hbzzEDqz6Y7iX5WVWtHsd2bgXcAX6d7VcU+wH8Gbk5yQFU9Nq6tlLaQYSD1Z9OZQd9nBc2KqrqqtyDJl4EfAacB545D26QxMwyk/mxRGFTVc5vmk+xI986iDXQDzm8at9ZJY+SYgTSC9vbRhW1xVGGQZPskf5LkEeBZ4ElgLd3zCLuOa0OlMfDMQBrZFg0eN58F/iPwF8B36G5DfRn4DH4Y0zTicwbSBEqyAfhGVb1/UPnPgAeq6vApaZg0iJ9MpIn1EpDegiSn0N1VJE0bXiaSJtZy4NQkP6e7g+hg4LeBB6e0VdIghoE0sT4I/JIuAE4DVgJLgT+dykZJgzlmIElyzECSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJAH/H0IlOeoP7ApYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  0.9572374767241588\n",
      "Incorrect:  0.04276252327584122\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#how's it doing for accreted stars\n",
    "#the model save/load between cells isn't strictly necessary,\n",
    "#but ipython notebooks allow us to not have to re-run the entire program to use \n",
    "#the generated model!\n",
    "#Here we load the saved model:\n",
    "model = keras.models.load_model(\"models/auriga_test.h5\")\n",
    "#And we'll compare its performance with the accreted evaluation stars:\n",
    "pred_acc = model.predict(test_dat.loc[test_lab == 1])\n",
    "THRESHOLD = 0.75\n",
    "#We can then split this pop into correct (P_a > THRESHOLD)\n",
    "guess_acc_fi = (pred_acc >= THRESHOLD)\n",
    "#And those below 0.5\n",
    "#We leave the between-ers in a sort of \"limbo\"\n",
    "#since the model considers them likely-accreted (>0.5),\n",
    "#but it's not confident enough for us to care\n",
    "wrong_guess_acc_fi = (pred_acc < 0.5)\n",
    "#output the performance fractions\n",
    "print(\"Correct: \",1.0*len(pred_acc[guess_acc_fi])/ len(pred_acc))\n",
    "print(\"Incorrect: \",1.0*len(pred_acc[wrong_guess_acc_fi])/ len(pred_acc))\n",
    "#And create a quick histogram of the P_a distribution of accreted stars\n",
    "plt.hist(pred_acc, bins=25)\n",
    "plt.title(\"Accreted Stars\")\n",
    "plt.xlabel(r\"$P_{\\rm a}$\",fontsize=24)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "#Now we select the in-situ stars\n",
    "pred_ins = model.predict(test_dat[test_lab == 0])\n",
    "#and do the same. \n",
    "#For in-situ, incorrect is P_a > 0.5\n",
    "guess_acc_fi = (pred_ins < 0.5)\n",
    "wrong_guess_acc_fi = (pred_ins >= 0.5)\n",
    "print(\"Correct: \",1.0*len(pred_ins[guess_acc_fi])/ len(pred_ins))\n",
    "print(\"Incorrect: \",1.0*len(pred_ins[wrong_guess_acc_fi])/ len(pred_ins))\n",
    "#And make a pretty little histogram\n",
    "plt.hist(pred_ins, bins=25)\n",
    "plt.title(\"In-Situ Stars\")\n",
    "plt.xlabel(r\"$P_{\\rm a}$\",fontsize=24)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
